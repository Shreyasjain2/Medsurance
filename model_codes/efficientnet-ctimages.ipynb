{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 1432479,
     "sourceType": "datasetVersion",
     "datasetId": 839140
    },
    {
     "sourceId": 10821900,
     "sourceType": "datasetVersion",
     "datasetId": 6719219
    },
    {
     "sourceId": 10821928,
     "sourceType": "datasetVersion",
     "datasetId": 6719236
    }
   ],
   "dockerImageVersionId": 30919,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "pip install torch torchvision efficientnet-pytorch tqdm scikit-learn seaborn matplotlib",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-22T10:26:24.630968Z",
     "iopub.execute_input": "2025-02-22T10:26:24.631293Z",
     "iopub.status.idle": "2025-02-22T10:26:30.662325Z",
     "shell.execute_reply.started": "2025-02-22T10:26:24.631265Z",
     "shell.execute_reply": "2025-02-22T10:26:30.661457Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Training",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom efficientnet_pytorch import EfficientNet\nimport os\nfrom tqdm import tqdm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\nclass CTScanClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(CTScanClassifier, self).__init__()\n        # Load pre-trained EfficientNetB0\n        self.efficient_net = EfficientNet.from_pretrained('efficientnet-b0')\n        # Modify the classifier\n        num_ftrs = self.efficient_net._fc.in_features\n        self.efficient_net._fc = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(num_ftrs, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.efficient_net(x)\n\ndef create_dataloaders(data_path, batch_size=32):\n    # Data transforms\n    data_transforms = {\n        'train': transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n        'valid': transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ]),\n        'test': transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n    }\n    \n    # Create datasets\n    image_datasets = {\n        x: ImageFolder(os.path.join(data_path, x), data_transforms[x])\n        for x in ['train', 'valid', 'test']\n    }\n    \n    # Create dataloaders\n    dataloaders = {\n        x: DataLoader(image_datasets[x], batch_size=batch_size,\n                     shuffle=True if x == 'train' else False,\n                     num_workers=4)\n        for x in ['train', 'valid', 'test']\n    }\n    \n    return dataloaders, image_datasets\n\ndef train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    \n    best_acc = 0.0\n    best_model_wts = None\n    \n    # For plotting\n    train_losses = []\n    val_losses = []\n    train_accs = []\n    val_accs = []\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n        \n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            running_loss = 0.0\n            running_corrects = 0\n            \n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            \n            if phase == 'train':\n                scheduler.step()\n                \n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n            \n            if phase == 'train':\n                train_losses.append(epoch_loss)\n                train_accs.append(epoch_acc.cpu())\n            else:\n                val_losses.append(epoch_loss)\n                val_accs.append(epoch_acc.cpu())\n            \n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n            \n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict().copy()\n                # Save checkpoint\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'best_acc': best_acc,\n                }, f'checkpoint_epoch_{epoch}.pth')\n    \n    print(f'Best val Acc: {best_acc:4f}')\n    model.load_state_dict(best_model_wts)\n    return model, train_losses, val_losses, train_accs, val_accs\n\ndef evaluate_model(model, test_loader):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.eval()\n    model = model.to(device)\n    \n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    # Print classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(all_labels, all_preds, \n                              target_names=test_loader.dataset.classes))\n    \n    return cm, all_preds, all_labels\n\ndef plot_training_curves(train_losses, val_losses, train_accs, val_accs):\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Training Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.title('Loss Curves')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(train_accs, label='Training Accuracy')\n    plt.plot(val_accs, label='Validation Accuracy')\n    plt.title('Accuracy Curves')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig('training_curves.png')\n    plt.close()\n\ndef plot_confusion_matrix(cm, classes):\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=classes, yticklabels=classes)\n    plt.title('Confusion Matrix')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.tight_layout()\n    plt.savefig('confusion_matrix.png')\n    plt.close()\n\ndef main():\n    # Set random seed for reproducibility\n    torch.manual_seed(42)\n    \n    # Hyperparameters\n    BATCH_SIZE = 32\n    NUM_EPOCHS = 25\n    LEARNING_RATE = 0.001\n    \n    # Create dataloaders\n    dataloaders, image_datasets = create_dataloaders(\"/kaggle/input/chest-ctscan-images/Data\", BATCH_SIZE)\n    \n    # Create model\n    num_classes = len(image_datasets['train'].classes)\n    model = CTScanClassifier(num_classes)\n    \n    # Loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n    \n    # Learning rate scheduler\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n    \n    # Train model\n    model, train_losses, val_losses, train_accs, val_accs = train_model(\n        model, dataloaders, criterion, optimizer, scheduler, NUM_EPOCHS\n    )\n    \n    # Plot training curves\n    plot_training_curves(train_losses, val_losses, train_accs, val_accs)\n    \n    # Evaluate on test set\n    cm, preds, labels = evaluate_model(model, dataloaders['test'])\n    \n    # Plot confusion matrix\n    plot_confusion_matrix(cm, image_datasets['test'].classes)\n\nif __name__ == \"__main__\":\n    main()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-22T10:26:33.291402Z",
     "iopub.execute_input": "2025-02-22T10:26:33.291753Z",
     "iopub.status.idle": "2025-02-22T10:28:55.076620Z",
     "shell.execute_reply.started": "2025-02-22T10:26:33.291719Z",
     "shell.execute_reply": "2025-02-22T10:28:55.075902Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Test Inferences",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn\nfrom PIL import Image\nimport torchvision.transforms as transforms\nfrom efficientnet_pytorch import EfficientNet\nimport matplotlib.pyplot as plt\n\nclass CTScanClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(CTScanClassifier, self).__init__()\n        self.efficient_net = EfficientNet.from_pretrained('efficientnet-b0')\n        num_ftrs = self.efficient_net._fc.in_features\n        self.efficient_net._fc = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(num_ftrs, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.efficient_net(x)\n\ndef load_model(checkpoint_path, num_classes):\n    model = CTScanClassifier(num_classes)\n    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n    return model\n\ndef predict_and_plot_image(model, image_path, class_names):\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n    \n    image = Image.open(image_path).convert('RGB')\n    image_tensor = transform(image).unsqueeze(0)\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    image_tensor = image_tensor.to(device)\n    \n    with torch.no_grad():\n        outputs = model(image_tensor)\n        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n        probability, predicted_idx = torch.max(probabilities, 1)\n    \n    predicted_class = class_names[predicted_idx.item()]\n    confidence = probability.item() * 100\n    \n    all_probabilities = probabilities[0].cpu().numpy() * 100\n    class_probabilities = {class_name: prob for class_name, prob in zip(class_names, all_probabilities)}\n    \n    plt.figure(figsize=(12, 6))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(image)\n    plt.title(f'Prediction: {predicted_class}\\nConfidence: {confidence:.2f}%')\n    plt.axis('off')\n    \n    plt.subplot(1, 2, 2)\n    classes = list(class_probabilities.keys())\n    probs = list(class_probabilities.values())\n    \n    bars = plt.bar(range(len(classes)), probs)\n    plt.xlabel('Classes')\n    plt.ylabel('Probability (%)')\n    plt.title('Class Probabilities')\n    plt.xticks(range(len(classes)), classes, rotation=45)\n    \n    for bar in bars:\n        height = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.1f}%',\n                ha='center', va='bottom')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return predicted_class, confidence, class_probabilities\n\ndef main():\n    checkpoint_path = '/kaggle/working/checkpoint_epoch_19.pth'\n    test_image_path = '/kaggle/input/ct-test3/test3.jpg'\n    class_names = ['adenocarcinoma', 'large.cell.carcinoma', 'normal', 'squamous.cell.carcinoma']\n    \n    model = load_model(checkpoint_path, len(class_names))\n    predicted_class, confidence, class_probabilities = predict_and_plot_image(model, test_image_path, class_names)\n    \n    print(f\"\\nPredicted class: {predicted_class}\")\n    print(f\"Confidence: {confidence:.2f}%\")\n    print(\"\\nProbabilities for all classes:\")\n    for class_name, prob in class_probabilities.items():\n        print(f\"{class_name}: {prob:.2f}%\")\n\nif __name__ == \"__main__\":\n    main()\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-22T10:48:49.313393Z",
     "iopub.execute_input": "2025-02-22T10:48:49.313760Z",
     "iopub.status.idle": "2025-02-22T10:48:49.836064Z",
     "shell.execute_reply.started": "2025-02-22T10:48:49.313731Z",
     "shell.execute_reply": "2025-02-22T10:48:49.835228Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
